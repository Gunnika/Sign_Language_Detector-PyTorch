{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import string\n",
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from barbar import Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw = np.array(glob('asl-alphabet/asl_alphabet_train/asl_alphabet_train/*/*'))\n",
    "test_data_raw = np.array(glob('asl-alphabet/asl_alphabet_test/asl_alphabet_test/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 87000 total train images.\n",
      "There are 28 total test images.\n"
     ]
    }
   ],
   "source": [
    "print('There are %d total train images.' % len(train_data_raw))\n",
    "print('There are %d total test images.' % len(test_data_raw)) #No test image for delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 69600 total train images.\n",
      "There are 17400 total dog validation images.\n",
      "There are 28 total test images.\n"
     ]
    }
   ],
   "source": [
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2\n",
    "\n",
    "train_transform = transforms.Compose([ transforms.Grayscale(num_output_channels=1),\n",
    "                                transforms.Resize(size=(50,50)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.5], [0.5])])\n",
    "valid_transform = transforms.Compose([ transforms.Grayscale(num_output_channels=1),\n",
    "                                    transforms.Resize(50),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.5], [0.5])])\n",
    "test_transform = transforms.Compose([ transforms.Grayscale(num_output_channels=1),\n",
    "                                    transforms.Resize(size=(50,50)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.5], [0.5])])\n",
    "\n",
    "train_data = datasets.ImageFolder(root = 'asl-alphabet/asl_alphabet_train/asl_alphabet_train', transform=train_transform)\n",
    "test_data = datasets.ImageFolder(root='asl-alphabet/asl_alphabet_test', transform=test_transform)\n",
    "\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "# define samplers for obtaining training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# print number of images in each dataset\n",
    "print('There are %d total train images.' % len(indices[split:]))\n",
    "print('There are %d total dog validation images.' % len(indices[:split]))\n",
    "print('There are %d total test images.' % len(test_data))\n",
    "\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=20,sampler=train_sampler)\n",
    "validloader = torch.utils.data.DataLoader(train_data, batch_size=20,sampler=valid_sampler)\n",
    "testloader = torch.utils.data.DataLoader(test_data,batch_size=20, shuffle=False)\n",
    "\n",
    "\n",
    "loaders = dict(train=trainloader,\n",
    "                       valid = validloader,\n",
    "                       test=testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,3)\n",
    "        self.conv2 = nn.Conv2d(10,20,3)\n",
    "        self.conv3 = nn.Conv2d(20,30,3)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.dropout = nn.Dropout2d(0.2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(2430, 270)\n",
    "        self.fc2 = nn.Linear(270,29)\n",
    "        \n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.softmax(F.relu(self.fc2(x)))\n",
    "        return(x)\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# move model to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model = Network().cuda()\n",
    "else:\n",
    "    model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 10, 48, 48]             100\n",
      "         MaxPool2d-2           [-1, 10, 24, 24]               0\n",
      "            Conv2d-3           [-1, 20, 22, 22]           1,820\n",
      "         MaxPool2d-4           [-1, 20, 11, 11]               0\n",
      "            Conv2d-5             [-1, 30, 9, 9]           5,430\n",
      "         Dropout2d-6             [-1, 30, 9, 9]               0\n",
      "            Linear-7                  [-1, 270]         656,370\n",
      "            Linear-8                   [-1, 29]           7,859\n",
      "        LogSoftmax-9                   [-1, 29]               0\n",
      "================================================================\n",
      "Total params: 671,579\n",
      "Trainable params: 671,579\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.35\n",
      "Params size (MB): 2.56\n",
      "Estimated Total Size (MB): 2.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (1,dim,dim)) #takes the model and the input tensor shape, displays the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), learning_rate, momentum=0.007)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        print('Epoch: {} '.format(\n",
    "        epoch\n",
    "        ))\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(Bar(loaders['train'])):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## find the loss and update the model parameters accordingly\n",
    "            ## record the average training loss, using something like\n",
    "            ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss = train_loss + ((1/(batch_idx +1))*(loss.data - train_loss))\n",
    "            \n",
    "#             if batch_idx % 1000 == 0:\n",
    "#                 print('Epoch %d, Batch %d loss: %.6f' %(epoch, batch_idx + 1, train_loss))\n",
    "            \n",
    "#         print('Training Loss: {:.6f} '.format(\n",
    "#         train_loss\n",
    "#         ))\n",
    "                \n",
    "    # return trained model\n",
    "#     return model\n",
    "            \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            output = model(data)\n",
    "            loss = criterion(output,target)\n",
    "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "\n",
    "\n",
    "#       print training/validation statistics \n",
    "        print('  Training Loss: {:.6f} \\tValidation Loss: {:.6f}'.format( \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        ## save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "            \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \n",
      "69600/87000: [===============================>] - ETA 0.2sssEpoch: 1 \tTraining Loss: 3.367000 \tValidation Loss: 3.365843\n",
      "Validation loss decreased (inf --> 3.365843).  Saving model ...\n",
      "Epoch: 2 \n",
      "69600/87000: [===============================>] - ETA 0.0sssEpoch: 2 \tTraining Loss: 3.364825 \tValidation Loss: 3.362534\n",
      "Validation loss decreased (3.365843 --> 3.362534).  Saving model ...\n",
      "Epoch: 3 \n",
      "69600/87000: [===============================>] - ETA 0.0sssEpoch: 3 \tTraining Loss: 3.359391 \tValidation Loss: 3.351774\n",
      "Validation loss decreased (3.362534 --> 3.351774).  Saving model ...\n",
      "Epoch: 4 \n",
      "69600/87000: [===============================>] - ETA 0.0sssEpoch: 4 \tTraining Loss: 3.333421 \tValidation Loss: 3.296326\n",
      "Validation loss decreased (3.351774 --> 3.296326).  Saving model ...\n",
      "Epoch: 5 \n",
      "69600/87000: [===============================>] - ETA 0.0sssEpoch: 5 \tTraining Loss: 3.219409 \tValidation Loss: 3.070334\n",
      "Validation loss decreased (3.296326 --> 3.070334).  Saving model ...\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model_scratch = train(epochs, loaders, model, optimizer, criterion, use_cuda, 'saved_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model that got the best validation accuracy \n",
    "model_scratch.load_state_dict(torch.load('saved_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.562278\n",
      "\n",
      "\n",
      "Test Accuracy:  7% ( 2/28)\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * float(correct / total), correct, total))\n",
    "\n",
    "# call test function    \n",
    "test(loaders, model_scratch, criterion, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_labels = {\n",
    "    0:'A',\n",
    "    1:'B',\n",
    "    2:'C',\n",
    "    3:'D',\n",
    "    4:'E',\n",
    "    5:'F',\n",
    "    6:'G',\n",
    "    7:'H',\n",
    "    8:'I',\n",
    "    9:'J',\n",
    "    10:'K',\n",
    "    11:'L',\n",
    "    12:'M',\n",
    "    13:'N',\n",
    "    14:'O',\n",
    "    15:'P',\n",
    "    16:'Q',\n",
    "    17:'R',\n",
    "    18:'S',\n",
    "    19:'T',\n",
    "    20:'U',\n",
    "    21:'V',\n",
    "    22:'W',\n",
    "    23:'X',\n",
    "    24:'Y',\n",
    "    25:'Z',\n",
    "    26:'del',\n",
    "    27:'nothing',\n",
    "    28:'space'\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_path):\n",
    "    # load the image and return the predicted breed\n",
    "    img = Image.open(img_path)\n",
    "#     img = Image.open(img_path).convert('L')\n",
    "    transformations = transforms.Compose([transforms.Grayscale(num_output_channels=1),\n",
    "                                            transforms.Resize(size=50),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.5],[0.5])])\n",
    "    image_tensor = transformations(img)[:3,:,:].unsqueeze(0)\n",
    "\n",
    "    # move model inputs to cuda, if GPU available\n",
    "    if use_cuda:\n",
    "        image_tensor = image_tensor.cuda()\n",
    "\n",
    "    # get sample outputs\n",
    "    output = model_scratch(image_tensor)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "\n",
    "    pred = np.squeeze(preds_tensor.numpy()[0]) if not use_cuda else np.squeeze(preds_tensor.cpu().numpy()[0])\n",
    "\n",
    "    return dict_labels[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,8))\n",
    "# plt.plot(loss_log[2:])\n",
    "# plt.plot(acc_log)\n",
    "# plt.plot(np.ones(len(acc_log)), linestyle='dashed')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict('Inference_Images/c.jpg')\n",
    "lab = 'c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: nothing\n",
      "Actual Label: c\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction: {}\".format(prediction))\n",
    "print(\"Actual Label: {}\".format(lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixels = cv2.imread('./c.jpg').reshape(28, 28)\n",
    "# plt.subplot(223)\n",
    "# sns.heatmap(data=pixels)\n",
    "# lab = 'c'\n",
    "# test_sample = torch.FloatTensor([pixels.reshape(1, 28, 28).tolist()])\n",
    "# pred = model(Variable(input_img))\n",
    "# print(\"Prediction: {}\".format(alph[torch.max(net_out_sample.data, 1)[1].numpy()[0]]))\n",
    "# print(\"Actual Label: {}\".format(lab))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
